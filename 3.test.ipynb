{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a36f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S67.15=-17.14/64.11+67.42E'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run common.ipynb\n",
    "\n",
    "tokenizer.decode(tokenizer.get_data(third_number=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f646376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelGEN(\n",
       "  (feature): LlamaModel(\n",
       "    (embed_tokens): Embedding(22, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (o_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (up_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (down_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (fc_out): Linear(in_features=64, out_features=22, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dpo = torch.load('dpo.model')\n",
    "model_dpo.to(device)\n",
    "model_dpo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9d94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-3347.07= 76.73*-44.68+69.33E 11.896400000000085\n",
      "S-46.36= 15.06+-9.76+-50.52E 1.1400000000000006\n",
      "S-2453.98= 38.12*-66.54+90.03E 7.505200000000059\n",
      "S87.83= 39.35-35.49+84.45E 0.480000000000004\n",
      "S214.55= 83.04--58.40+74.89E 1.7799999999999727\n",
      "S-19.25= 85.67/12.06+-25.23E 1.1236484245439442\n",
      "S-50.75= -87.42--19.88+16.68E 0.11000000000000654\n",
      "S3117.25= 42.12*73.58+-33.46E 51.520400000000336\n",
      "S13.25= -79.81/37.58+14.06E 1.3137360298030867\n",
      "S-134.32= -39.98+-49.73+-43.26E 1.3499999999999943\n",
      "S-335.11= -2.70*90.90+-72.82E 16.860000000000014\n",
      "S206.49= 98.44--27.58+83.02E 2.549999999999983\n",
      "S-61.36= -64.00+-30.87+32.29E 1.220000000000006\n",
      "S-230.41= -75.86*2.19+-21.21E 43.066599999999994\n",
      "S6325.83= 80.65*76.95+31.70E 88.11249999999927\n",
      "S481.63= 23.51*21.53+-90.58E 66.03969999999993\n",
      "S30.93= -46.78/92.95+31.63E 0.1967186659494331\n",
      "S-4074.22= -78.24*51.01+-93.36E 10.162399999999707\n",
      "S-51.24= 12.16/-98.35+-51.29E 0.17364006100660845\n",
      "S1420.00= -72.38*-18.37+98.15E 7.770600000000059\n",
      "S-807.30= -9.51*77.25+-63.52E 9.132499999999936\n",
      "S3.50= 8.72-97.47+98.37E 6.1200000000000045\n",
      "S-28.93= 34.69/53.18+-29.41E 0.17231289958630924\n",
      "S97.55= 64.93/-93.17+98.45E 0.20310185682086512\n",
      "S22.16= 57.72--10.31+-44.42E 1.4499999999999993\n",
      "S-34.17= 70.73+-33.35+-68.21E 3.3400000000000105\n",
      "S3593.54= -61.43*-57.59+12.98E 42.80629999999974\n",
      "S-1273.03= 33.98*-42.15+96.56E 62.666999999999916\n",
      "S363.16= 29.61*7.62+91.63E 45.90180000000004\n",
      "S-119.09= -45.70-38.14+-32.23E 3.0200000000000102\n",
      "S55.32= 46.20-9.94+19.14E 0.0800000000000054\n",
      "S-69.62= -66.39/64.14+-68.16E 0.42492048643592284\n",
      "S15.11= 32.62/-68.96+15.03E 0.5530278422273778\n",
      "S-18.98= -55.28+5.63+30.90E 0.23000000000000043\n",
      "S-78.61= 12.74/41.81+-78.17E 0.744711791437453\n",
      "S4137.22= 77.36*54.37+-75.66E 6.816800000000512\n",
      "S86.23= 92.84+-23.82+17.45E 0.2400000000000091\n",
      "S1437.78= 47.50*31.23+-36.87E 8.775000000000091\n",
      "S35.51= -6.78/59.51+35.76E 0.13606956813980986\n",
      "S79.09= -6.42+97.91+-12.53E 0.13000000000000966\n",
      "S14.01= -35.37/28.16+15.23E 0.03603693181818102\n",
      "S158.45= 54.17+37.22+64.43E 2.6299999999999955\n",
      "S27.45= 30.07-92.36+88.87E 0.8699999999999939\n",
      "S-114.32= -68.45--61.01+-99.74E 7.139999999999986\n",
      "S-47.26= -19.90/70.71+-47.33E 0.35143119785037413\n",
      "S81.61= 8.88+60.83+10.06E 1.8400000000000034\n",
      "S103.27= -7.91+17.85+93.04E 0.28999999999999204\n",
      "S-99.96= -64.93-20.89+-13.31E 0.8299999999999841\n",
      "S-48.45= -20.89/61.04+-47.72E 0.38776539973788005\n",
      "S-194.21= -27.75-72.38+-95.86E 1.7800000000000011\n",
      "S-207.50= -88.56+-39.19+-79.19E 0.5600000000000023\n",
      "S-52.18= -0.78*-44.41+-92.10E 5.280199999999994\n",
      "S35.15= 86.63+-20.69+-30.28E 0.509999999999998\n",
      "S40.95= 93.06+16.56+-69.28E 0.6099999999999994\n",
      "S-37.72= -66.31-8.99+38.06E 0.480000000000004\n",
      "S132.02= 86.11-15.86+62.49E 0.7199999999999989\n",
      "S-42.02= 14.39-38.97+-16.95E 0.490000000000002\n",
      "S-441.85= -7.81*68.32+95.35E 3.620800000000145\n",
      "S-456.73= 30.32*-9.62+-63.55E 101.50160000000005\n",
      "S52.01= 54.75/-55.52+53.66E 0.6638688760806915\n",
      "S-0.20= -63.82+7.56+53.61E 2.4499999999999984\n",
      "S64.74= -55.23+39.44+80.26E 0.269999999999996\n",
      "S69.44= 11.53+-28.83+86.96E 0.21999999999999886\n",
      "S-104.76= -54.53+-59.84+7.98E 1.6299999999999955\n"
     ]
    }
   ],
   "source": [
    "#随机一批数据\n",
    "input_ids = [tokenizer.get_data(third_number=True) for i in range(64)]\n",
    "\n",
    "#切分成question和answer\n",
    "split = [i.index(tokenizer.encoder['=']) + 1 for i in input_ids]\n",
    "question = [input_ids[i][:split[i]] for i in range(len(input_ids))]\n",
    "answer = [input_ids[i][split[i]:] for i in range(len(input_ids))]\n",
    "\n",
    "#根据question生成predict\n",
    "input_ids = [torch.LongTensor(i).unsqueeze(0).to(device) for i in question]\n",
    "predict = [generate(model_dpo, i) for i in input_ids]\n",
    "\n",
    "#裁剪,只要生成的部分\n",
    "predict = [p[0].tolist()[len(q):] for p, q in zip(predict, question)]\n",
    "\n",
    "#解码成文本\n",
    "question = [tokenizer.decode(i) for i in question]\n",
    "answer = [tokenizer.decode(i) for i in answer]\n",
    "predict = [tokenizer.decode(i) for i in predict]\n",
    "\n",
    "for q, a, p in zip(question, answer, predict):\n",
    "    try:\n",
    "        diff = abs(float(q[1:-1]) - eval(p[:p.index('E')]))\n",
    "    except:\n",
    "        diff = abs(float(q[1:-1]))\n",
    "\n",
    "    print(q, p, diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
